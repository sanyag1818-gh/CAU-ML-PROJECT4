{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":14348714,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport joblib\nimport lightgbm as lgb\nimport kaggle_evaluation.default_inference_server\n\n#CONFIG STUFF\n\nKAGGLE_INPUT_PATH = \"/kaggle/input/hull-tactical-market-prediction/\"\nMODEL_SAVE_PATH = \"/tmp/final_lgbm_model.pkl\"  \nTARGET_COL = \"market_forward_excess_returns\"\n\n#So this function converts our predictions to portfolio weights\n#Using tanh because it works well in practice.\ndef convert_predictions_to_weights(preds):\n    preds = np.asarray(preds)\n    # Standardize first\n    z_scores = (preds - preds.mean()) / (preds.std() + 1e-9)  # avoid division by zero\n    weights = 1.0 + np.tanh(z_scores)  # maps to [0, 2] range\n    return np.clip(weights, 0.0, 2.0)  # just to be extra safe\n\n#Global vars-not ideal but works for this use case\nmodel_instance = None\nfeature_list = []\nis_model_loaded = False\n#TRAINING PHASE-runs once when notebook starts\n\ntry:\n    training_file = Path(KAGGLE_INPUT_PATH) / \"train.csv\"\n    train_df = pd.read_csv(training_file)\n    \n    print(f\"Loaded training data with {len(train_df)} rows\")\n\n    # Feature engineering - excluding obvious non-predictive columns\n    cols_to_exclude = [\"date_id\", \"forward_returns\", \"risk_free_rate\", TARGET_COL]\n    \n    #Getting all numeric columns that aren't in the exclude list\n    numeric_features = []\n    for col in train_df.columns:\n        if col not in cols_to_exclude and np.issubdtype(train_df[col].dtype, np.number):\n            numeric_features.append(col)\n    \n    feature_list = numeric_features.copy()\n    print(f\"Selected {len(feature_list)} features for training\")\n\n    #Data cleaning-converting everything to proper numeric format\n    for feature in feature_list:\n        train_df[feature] = pd.to_numeric(train_df[feature], errors=\"coerce\")\n\n    #Removing rows where target is missing (can't train on those)\n    train_df = train_df.dropna(subset=[TARGET_COL])\n    print(f\"After cleaning: {len(train_df)} training samples\")\n\n    #Preparing training data\n    X_train = train_df[feature_list]\n    y_train = train_df[TARGET_COL].astype(float)\n\n    #LightGBM setup -these parameters worked well in experiments from NotebookA\n    lgbm_model = lgb.LGBMRegressor(\n        objective=\"regression\",\n        metric=\"rmse\",\n        n_estimators=900,      #Maybe morethanrequired\n        learning_rate=0.05,    #conservative learning rate\n        num_leaves=100,\n        max_depth=10,\n        n_jobs=-1,             #use all available cores\n        random_state=42,       #for reproducibility\n        verbose=-1,            #quiet training\n    )\n\n    print(\"Starting model training...\")\n    lgbm_model.fit(X_train, y_train)\n    print(\"Training completed successfully!\")\n\n    #Saving the trained model and feature names\n    model_data = {\n        \"model\": lgbm_model,\n        \"features\": feature_list\n    }\n    joblib.dump(model_data, MODEL_SAVE_PATH)\n    print(f\"Model saved to: {MODEL_SAVE_PATH}\")\n\nexcept Exception as error:\n    print(f\"Training failed with error: {error}\")\n    #Creating a dummy model as fallback\n    class FallbackModel:\n        def predict(self, X):\n            return np.zeros(len(X))  # return zeros if everything fails\n    \n    fallback_data = {\"model\": FallbackModel(), \"features\": []}\n    joblib.dump(fallback_data, MODEL_SAVE_PATH)\n    print(\"Created fallback model\")\n    \n# PREDICTION FUNCTION -Which is found on Kaggle's evaluation system\n\ndef predict(test_data: pl.DataFrame) -> float:\n    \"\"\"\n    This gets called for each test sample during live evaluation.\n    Returns a portfolio weight between 0 and 2.\n    \"\"\"\n    global is_model_loaded, model_instance, feature_list\n\n    # Load model on first call (lazy loading)\n    if not is_model_loaded:\n        try:\n            saved_data = joblib.load(MODEL_SAVE_PATH)\n            model_instance = saved_data[\"model\"]\n            feature_list = saved_data[\"features\"]\n            is_model_loaded = True\n            print(\"Model loaded successfully for inference\")\n        except Exception as load_error:\n            print(f\"Failed to load model: {load_error}\")\n            return 1.0  # return neutral weight as fallback\n\n    # Convert polars to pandas (easier to work with)\n    if isinstance(test_data, pl.DataFrame):\n        test_df = test_data.to_pandas()\n    else:\n        test_df = test_data\n\n    #Prepare feature matrix for prediction\n    X_pred = pd.DataFrame(index=test_df.index)\n    \n    #Fill in features, using NaN for missing ones\n    for feature_name in feature_list:\n        if feature_name in test_df.columns:\n            X_pred[feature_name] = pd.to_numeric(test_df[feature_name], errors=\"coerce\")\n        else:\n            X_pred[feature_name] = np.nan  # LightGBM can handle NaN values\n\n    #Get prediction from model\n    prediction = float(model_instance.predict(X_pred[feature_list])[0])\n    \n    #Convert raw prediction to portfolio weight\n    portfolio_weight = convert_predictions_to_weights([prediction])[0]\n\n    return float(portfolio_weight)\n#STARTING THE INFERENCE SERVER\n#Setting up the inference server\nserver = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\n#Run in appropriate mode based on environment\nif os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n    print(\"Running in competition mode...\")\n    server.serve()\nelse:\n    print(\"Running in local test mode...\")\n    server.run_local_gateway((KAGGLE_INPUT_PATH,))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T04:33:14.413606Z","iopub.execute_input":"2025-11-21T04:33:14.413975Z","iopub.status.idle":"2025-11-21T04:33:30.411023Z","shell.execute_reply.started":"2025-11-21T04:33:14.413949Z","shell.execute_reply":"2025-11-21T04:33:30.410115Z"}},"outputs":[{"name":"stdout","text":"Loaded training data with 9021 rows\nSelected 94 features for training\nAfter cleaning: 9021 training samples\nStarting model training...\nTraining completed successfully!\nModel saved to: /tmp/final_lgbm_model.pkl\nRunning in local test mode...\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/templates.py:95: RuntimeWarning: 1006 seconds elapsed before server startup.\n                This exceeds the startup time limit of 900 seconds that the gateway will enforce\n                during the rerun on the hidden test set. Start the server before performing any time consuming steps.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Model loaded successfully for inference\n","output_type":"stream"}],"execution_count":8}]}