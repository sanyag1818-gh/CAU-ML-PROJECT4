{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ed1176cc-db38-4503-ae75-28d8a3429158",
      "metadata": {
        "id": "ed1176cc-db38-4503-ae75-28d8a3429158",
        "outputId": "cf7d4c87-a25e-458a-8915-306e3026857f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Step 1: Loading Data\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'BTC-USD.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1092061503.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Load data - use the file you uploaded to Jupyter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mbtc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BTC-USD.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mbtc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mbtc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BTC-USD.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "# Part 1: Data Loading and Basic Processing\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"Step 1: Loading Data\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load data - use the file you uploaded to Jupyter\n",
        "btc = pd.read_csv(\"BTC-USD.csv\", parse_dates=[\"Date\"])\n",
        "btc = btc.sort_values(\"Date\").reset_index(drop=True)\n",
        "btc[\"Date\"] = pd.to_datetime(btc[\"Date\"])\n",
        "\n",
        "print(f\"Original data shape: {btc.shape}\")\n",
        "print(f\"Date range: {btc['Date'].min()} to {btc['Date'].max()}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(btc.head())\n",
        "\n",
        "\n",
        "# Part 2: Feature Engineering\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Step 2: Feature Engineering\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. Calculate returns\n",
        "btc[\"returns\"] = btc[\"Close\"].pct_change()\n",
        "\n",
        "# 2. Calculate excess returns (simplified: risk-free rate = 0)\n",
        "risk_free_rate = 0.0\n",
        "btc[\"excess_returns\"] = btc[\"returns\"] - risk_free_rate\n",
        "\n",
        "# 3. Target variable: 5-day future excess returns\n",
        "horizon = 5\n",
        "btc[\"target_excess_ret\"] = btc[\"excess_returns\"].shift(-horizon)\n",
        "\n",
        "# 4. Technical indicator features\n",
        "btc[\"ret_1d\"] = btc[\"returns\"]\n",
        "btc[\"ret_5d\"] = btc[\"Close\"].pct_change(5)\n",
        "btc[\"ret_20d\"] = btc[\"Close\"].pct_change(20)\n",
        "\n",
        "# Price range features\n",
        "btc[\"range_pct\"] = (btc[\"High\"] - btc[\"Low\"]) / btc[\"Close\"]\n",
        "btc[\"upper_shadow\"] = (btc[\"High\"] - btc[\"Close\"]) / btc[\"Close\"]\n",
        "btc[\"lower_shadow\"] = (btc[\"Close\"] - btc[\"Low\"]) / btc[\"Close\"]\n",
        "\n",
        "# Volatility features\n",
        "btc[\"vol_5d\"] = btc[\"returns\"].rolling(5).std()\n",
        "btc[\"vol_20d\"] = btc[\"returns\"].rolling(20).std()\n",
        "\n",
        "# Volume features\n",
        "btc[\"vol_chg\"] = btc[\"Volume\"].pct_change()\n",
        "btc[\"vol_ma5\"] = btc[\"Volume\"].rolling(5).mean() / btc[\"Volume\"]\n",
        "\n",
        "# Moving average features\n",
        "btc[\"ma_5\"] = btc[\"Close\"].rolling(5).mean() / btc[\"Close\"]\n",
        "btc[\"ma_20\"] = btc[\"Close\"].rolling(20).mean() / btc[\"Close\"]\n",
        "\n",
        "# Remove missing values\n",
        "btc = btc.dropna()\n",
        "\n",
        "# Take first 500 samples (avoid excessive data size)\n",
        "btc = btc.iloc[:500].copy()\n",
        "\n",
        "print(f\"Processed data shape: {btc.shape}\")\n",
        "print(f\"Feature list: {btc.columns.tolist()}\")\n",
        "\n",
        "\n",
        "# Part 3: Prepare Training Data\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Step 3: Preparing Training Data\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Select features\n",
        "features = [\n",
        "    \"ret_1d\", \"ret_5d\", \"ret_20d\",\n",
        "    \"range_pct\", \"upper_shadow\", \"lower_shadow\",\n",
        "    \"vol_5d\", \"vol_20d\", \"vol_chg\", \"vol_ma5\",\n",
        "    \"ma_5\", \"ma_20\"\n",
        "]\n",
        "\n",
        "X = btc[features].values\n",
        "y = btc[\"target_excess_ret\"].values\n",
        "dates = btc[\"Date\"].values\n",
        "actual_returns = btc[\"excess_returns\"].values\n",
        "\n",
        "print(f\"Feature matrix X shape: {X.shape}\")\n",
        "print(f\"Target variable y shape: {y.shape}\")\n",
        "\n",
        "# Data normalization\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Split train/test sets (80/20)\n",
        "split_idx = int(len(X_scaled) * 0.8)\n",
        "\n",
        "X_train = X_scaled[:split_idx]\n",
        "X_test = X_scaled[split_idx:]\n",
        "y_train = y_scaled[:split_idx]\n",
        "y_test = y_scaled[split_idx:]\n",
        "\n",
        "# Save test set actual returns (for later strategy evaluation)\n",
        "test_returns = actual_returns[split_idx:]\n",
        "test_dates = dates[split_idx:]\n",
        "\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")\n",
        "\n",
        "# Reshape for LSTM input format (samples, timesteps, features)\n",
        "lookback = 1  # Use 1 timestep\n",
        "X_train = X_train.reshape((X_train.shape[0], lookback, X_train.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], lookback, X_test.shape[1]))\n",
        "\n",
        "print(f\"LSTM input shape: {X_train.shape}\")\n",
        "\n",
        "\n",
        "# Part 4: Build and Train Model\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Step 4: Building and Training Model\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Build improved LSTM model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.LSTM(128, return_sequences=True,\n",
        "                      input_shape=(lookback, len(features))),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.LSTM(64),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.summary()\n",
        "\n",
        "# Train model\n",
        "print(\"\\nStarting training...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "# Part 5: Prediction\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Step 5: Generating Predictions\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "y_pred_scaled = model.predict(X_test, verbose=0)\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled).flatten()\n",
        "y_test_original = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "\n",
        "print(f\"Prediction range: [{y_pred.min():.4f}, {y_pred.max():.4f}]\")\n",
        "print(f\"Actual value range: [{y_test_original.min():.4f}, {y_test_original.max():.4f}]\")\n",
        "\n",
        "\n",
        "# Part 6: Portfolio Strategy\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Step 6: Implementing Portfolio Strategy\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def compute_weights(predicted_returns, risk_aversion=10):\n",
        "    \"\"\"\n",
        "    Calculate allocation weights (0-2) based on predicted returns\n",
        "    \"\"\"\n",
        "    weights = []\n",
        "    for pred in predicted_returns:\n",
        "        if pred > 0:\n",
        "            # Positive return: weight between 0-2, higher return = higher weight\n",
        "            weight = min(2.0, max(0, pred * risk_aversion))\n",
        "        else:\n",
        "            # Negative return: weight = 0\n",
        "            weight = 0.0\n",
        "        weights.append(weight)\n",
        "    return np.array(weights)\n",
        "\n",
        "# Calculate initial weights\n",
        "initial_weights = compute_weights(y_pred, risk_aversion=10)\n",
        "\n",
        "# Calculate strategy returns\n",
        "# Note: Using actual returns after prediction time for strategy performance\n",
        "strategy_returns = initial_weights * test_returns\n",
        "\n",
        "# Benchmark returns (buy & hold strategy)\n",
        "benchmark_returns = test_returns\n",
        "\n",
        "# Calculate volatility\n",
        "strategy_vol = np.std(strategy_returns)\n",
        "benchmark_vol = np.std(benchmark_returns)\n",
        "vol_ratio = strategy_vol / benchmark_vol\n",
        "\n",
        "print(f\"Strategy volatility: {strategy_vol:.6f}\")\n",
        "print(f\"Benchmark volatility: {benchmark_vol:.6f}\")\n",
        "print(f\"Volatility ratio: {vol_ratio:.3f}\")\n",
        "\n",
        "# Apply volatility constraint (≤ 1.2× benchmark volatility)\n",
        "if vol_ratio > 1.2:\n",
        "    print(\"\\n  Violates volatility constraint, adjusting weights...\")\n",
        "    adjustment_factor = 1.2 / vol_ratio\n",
        "    adjusted_weights = initial_weights * adjustment_factor\n",
        "    strategy_returns = adjusted_weights * test_returns\n",
        "\n",
        "    # Recalculate volatility\n",
        "    strategy_vol = np.std(strategy_returns)\n",
        "    vol_ratio = strategy_vol / benchmark_vol\n",
        "    print(f\"Adjusted volatility ratio: {vol_ratio:.3f}\")\n",
        "else:\n",
        "    print(\"✓ Satisfies volatility constraint\")\n",
        "    adjusted_weights = initial_weights\n",
        "\n",
        "\n",
        "# Part 7: Evaluation Metrics\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Step 7: Computing Evaluation Metrics\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. Sharpe Ratio (annualized)\n",
        "def sharpe_ratio(returns, risk_free=0):\n",
        "    excess = returns - risk_free\n",
        "    if np.std(excess) == 0:\n",
        "        return 0\n",
        "    return np.mean(excess) / np.std(excess) * np.sqrt(252)\n",
        "\n",
        "strategy_sharpe = sharpe_ratio(strategy_returns)\n",
        "benchmark_sharpe = sharpe_ratio(benchmark_returns)\n",
        "\n",
        "# 2. Cumulative returns\n",
        "strategy_cumret = (1 + strategy_returns).prod() - 1\n",
        "benchmark_cumret = (1 + benchmark_returns).prod() - 1\n",
        "\n",
        "# 3. Maximum drawdown\n",
        "def max_drawdown(returns):\n",
        "    cum_returns = (1 + returns).cumprod()\n",
        "    running_max = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - running_max) / running_max\n",
        "    return drawdown.min()\n",
        "\n",
        "strategy_mdd = max_drawdown(strategy_returns)\n",
        "benchmark_mdd = max_drawdown(benchmark_returns)\n",
        "\n",
        "# 4. Annualized return\n",
        "def annualized_return(returns):\n",
        "    total_return = (1 + returns).prod()\n",
        "    n_days = len(returns)\n",
        "    return total_return ** (252 / n_days) - 1\n",
        "\n",
        "strategy_ann_ret = annualized_return(strategy_returns)\n",
        "benchmark_ann_ret = annualized_return(benchmark_returns)\n",
        "\n",
        "# Print results\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Evaluation Results Summary\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\n{'Metric':<20} {'Strategy':<15} {'Benchmark':<15}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'Sharpe Ratio':<20} {strategy_sharpe:>14.3f} {benchmark_sharpe:>14.3f}\")\n",
        "print(f\"{'Cumulative Return':<20} {strategy_cumret:>13.2%} {benchmark_cumret:>13.2%}\")\n",
        "print(f\"{'Annualized Return':<20} {strategy_ann_ret:>13.2%} {benchmark_ann_ret:>13.2%}\")\n",
        "print(f\"{'Maximum Drawdown':<20} {strategy_mdd:>13.2%} {benchmark_mdd:>13.2%}\")\n",
        "print(f\"{'Volatility':<20} {strategy_vol:>14.6f} {benchmark_vol:>14.6f}\")\n",
        "print(f\"{'Volatility Ratio':<20} {vol_ratio:>14.3f} {'1.000':>14}\")\n",
        "\n",
        "\n",
        "# Part 8: Visualization\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Step 8: Generating Visualizations\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# 1. Training loss curve\n",
        "axes[0, 0].plot(history.history['loss'], label='Training Loss')\n",
        "axes[0, 0].plot(history.history['val_loss'], label='Validation Loss')\n",
        "axes[0, 0].set_title('Model Training Loss')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Cumulative returns comparison\n",
        "strategy_cum = (1 + strategy_returns).cumprod()\n",
        "benchmark_cum = (1 + benchmark_returns).cumprod()\n",
        "\n",
        "axes[0, 1].plot(strategy_cum, label=f'Strategy (Sharpe: {strategy_sharpe:.2f})', linewidth=2)\n",
        "axes[0, 1].plot(benchmark_cum, label=f'Buy & Hold (Sharpe: {benchmark_sharpe:.2f})', linewidth=2)\n",
        "axes[0, 1].set_title('Cumulative Returns Comparison')\n",
        "axes[0, 1].set_xlabel('Days')\n",
        "axes[0, 1].set_ylabel('Cumulative Return')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Weight distribution\n",
        "axes[1, 0].hist(adjusted_weights, bins=30, edgecolor='black', alpha=0.7)\n",
        "axes[1, 0].axvline(adjusted_weights.mean(), color='red',\n",
        "                   linestyle='--', label=f'Mean: {adjusted_weights.mean():.2f}')\n",
        "axes[1, 0].set_title('Portfolio Weights Distribution')\n",
        "axes[1, 0].set_xlabel('Weight')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Drawdown curve\n",
        "def compute_drawdown(returns):\n",
        "    cum_returns = (1 + returns).cumprod()\n",
        "    running_max = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = (cum_returns - running_max) / running_max\n",
        "    return drawdown\n",
        "\n",
        "strategy_dd = compute_drawdown(strategy_returns)\n",
        "benchmark_dd = compute_drawdown(benchmark_returns)\n",
        "\n",
        "axes[1, 1].plot(strategy_dd, label=f'Strategy (Max: {strategy_mdd:.2%})', linewidth=2)\n",
        "axes[1, 1].plot(benchmark_dd, label=f'Benchmark (Max: {benchmark_mdd:.2%})', linewidth=2)\n",
        "axes[1, 1].set_title('Drawdown Comparison')\n",
        "axes[1, 1].set_xlabel('Days')\n",
        "axes[1, 1].set_ylabel('Drawdown')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "axes[1, 1].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n All steps completed!\")\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Summary\")\n",
        "print(\"=\" * 50)\n",
        "print(f\" Data processing: {len(btc)} samples\")\n",
        "print(f\" Feature engineering: {len(features)} features\")\n",
        "print(f\"✓ Model training: Completed\")\n",
        "print(f\"✓ Strategy implementation: Satisfies volatility constraint (≤ 1.2×)\")\n",
        "print(f\"✓ Strategy Sharpe Ratio: {strategy_sharpe:.3f}\")\n",
        "print(f\"✓ Excess return vs benchmark: {(strategy_cumret - benchmark_cumret):.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33aab01e-c355-4306-9e8f-fc9461d7d55e",
      "metadata": {
        "id": "33aab01e-c355-4306-9e8f-fc9461d7d55e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee842fe6-f0f5-4604-b937-cbbecdbc2327",
      "metadata": {
        "id": "ee842fe6-f0f5-4604-b937-cbbecdbc2327"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tf_env]",
      "language": "python",
      "name": "conda-env-tf_env-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}